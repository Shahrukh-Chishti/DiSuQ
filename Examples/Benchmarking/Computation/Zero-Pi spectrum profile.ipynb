{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e0ca4cb",
   "metadata": {},
   "source": [
    "* Zero-Pi spectrum profile on flux manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff523fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DiSuQ.Torch import models\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4bd0373",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = torch.device('cuda')\n",
    "torch.set_default_device(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abfc3099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(0).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "200f8838",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f09a825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/chishti/JupyterHub/DiSuQ/Torch/circuit.py\u001b[0m(318)\u001b[0;36mkermanDistribution\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    317 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 318 \u001b[0;31m        \u001b[0mNo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLn_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    319 \u001b[0;31m        \u001b[0mNj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mNi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mNo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> torch.linalg.matrix_rank(Ln_.detach()).dtype\n",
      "torch.int64\n",
      "ipdb> self.Nn\n",
      "3\n",
      "ipdb> matrix_rank(Ln_.detach().numpy())\n",
      "*** TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n",
      "ipdb> matrix_rank(Ln_.detach())\n",
      "*** TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n",
      "ipdb> Ln_.device\n",
      "device(type='cuda', index=0)\n",
      "ipdb> Ln_.device=='cuda'\n",
      "False\n",
      "ipdb> Ln_.iscuda()\n",
      "*** AttributeError: 'Tensor' object has no attribute 'iscuda'\n",
      "ipdb> Ln_.is_cuda\n",
      "True\n",
      "ipdb> Ln_.cpu().is_cuda\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "ZeroPi = models.zeroPi([10]*3,sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b0d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZeroPi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "368a39ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-16.1181, device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ZeroPi.circuitComposition()['Lx'].ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61afe02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flux = torch.tensor(.5,device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bc336f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacity of 47.45 GiB of which 1.52 GiB is free. Including non-PyTorch memory, this process has 45.75 GiB memory in use. Of the allocated memory 45.48 GiB is allocated by PyTorch, and 47.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mZeroPi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhamiltonianJosephson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mflux\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mflux\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/JupyterHub/DiSuQ/Torch/circuit.py:818\u001b[0m, in \u001b[0;36mCharge.hamiltonianJosephson\u001b[0;34m(self, external_fluxes)\u001b[0m\n\u001b[1;32m    816\u001b[0m     edge \u001b[38;5;241m=\u001b[39m u,v\n\u001b[1;32m    817\u001b[0m     flux \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloopFlux(u,v,key,external_fluxes)\n\u001b[0;32m--> 818\u001b[0m     H \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m E\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mJplus\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mphase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflux\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mJminus\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mphase\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mflux\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m H\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/env/lib/python3.11/site-packages/torch/utils/_device.py:77\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.82 GiB. GPU 0 has a total capacity of 47.45 GiB of which 1.52 GiB is free. Including non-PyTorch memory, this process has 45.75 GiB memory in use. Of the allocated memory 45.48 GiB is allocated by PyTorch, and 47.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "ZeroPi.hamiltonianJosephson({'Lx':flux,'Ly':flux})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705f366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8287229",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3b672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    H_LC = ZeroPi.hamiltonianLC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efb3063",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_LC = ZeroPi.hamiltonianLC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b1eb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "del H_LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72530aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
